{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a8b4c2-478e-4ae6-b94a-1df130abb004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pycocotools\n",
    "# !pip install ffmpeg\n",
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09984a1f-bd34-4814-a0b0-8339e7a0938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video, display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow.keras import layers, models\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ab4ee5-9c2b-4a97-8c66-bee96a655b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME = ['Paper', 'Rock', 'Scissor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e940cb22-f625-4099-9094-3f2b50e28bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_graber():\n",
    "    video_grab = Video(r\"C:\\Users\\Mewandi\\Desktop\\MI\\Neural_Network\\video.mp4\", width=400, height=300)\n",
    "    return video_grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab1cdf9-5e3f-4547-bc2f-e6fcc5c5cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_img(num_images=50, label='Null'):\n",
    "    img = []\n",
    "    y = []\n",
    "\n",
    "    for x in tqdm(range(num_images)):\n",
    "        new_img = np.array(video_graber(0))\n",
    "        img.append(new_img)\n",
    "\n",
    "        if label != 'Null':\n",
    "           y.append(label)\n",
    "\n",
    "    img = np.array(img)\n",
    "    y = np.array(y)\n",
    "    return img, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc5928c-7f18-453a-b574-414cb0b5639a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c02c0f01a441c69d0b59488338dd81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "video_graber() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m paper_img, paper_label \u001b[38;5;241m=\u001b[39m capture_img(num_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mcapture_img\u001b[1;34m(num_images, label)\u001b[0m\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_images)):\n\u001b[1;32m----> 6\u001b[0m     new_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(video_graber(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m      7\u001b[0m     img\u001b[38;5;241m.\u001b[39mappend(new_img)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNull\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: video_graber() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "paper_img, paper_label = capture_img(num_images=50, label='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2d7626-cf34-4b9f-95a0-5923c94db4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_img, rock_label = capture_img(num_images=50, label='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f3e42b-8f90-4756-bf14-386f55d44321",
   "metadata": {},
   "outputs": [],
   "source": [
    "scissor_img, scissor_label = capture_img(num_images=50, label='2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71bff7e-0f5a-4069-bdbd-b466f4c7c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = np.concatenate((paper_img, rock_img, scissor_img))\n",
    "train_img = train_img / 255\n",
    "train_label = np.concatenate((paper_label, rock_label, scissor_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4f86d-0723-45b3-ab26-8bc6bb647d13",
   "metadata": {},
   "source": [
    "### Data Generator to add more images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa64c520-7d37-48d7-854a-17f78a022519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "datagenerator = ImageDataGenerator(\n",
    "                                    rotation_range = 40,\n",
    "                                    width_shift_range = 0.2,\n",
    "                                    height_shift_range = 0.2,\n",
    "                                    shear_range = 0.2,\n",
    "                                    zoom_range = 0.2,\n",
    "                                    horizontal_flip = True,\n",
    "                                    file_mode = 'nearest', # To fill the empty spaces in video\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f207e8-a3df-4a60-80f5-7f713da40e41",
   "metadata": {},
   "source": [
    "#### Make new trains in 3D shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4618c907-cfe7-4534-905d-3ecee1d0244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "new_train_imgs = []\n",
    "new_train_labels = []\n",
    "\n",
    "for image in range(train_img):\n",
    "    img = image.reshape((1,)+image.shape) # make 3D shape. (1, ) it supposed to be like (1,400,300) but the 2d size is given in video function\n",
    "\n",
    "    i = 0\n",
    "    for batch in datagenerator.flow(img, save_prefix = 'test', save_format = 'jpeg'):\n",
    "        plt.figure(i)\n",
    "        plot = plt.imshow(batch[0])\n",
    "        i += 1\n",
    "        new_train_imgs.append(batch[0])\n",
    "        new_train_labels.append(train_label[idx]) # for adding the index into img\n",
    "    \n",
    "        if i > 10: # Each image should be added 10 differents shapes\n",
    "            break\n",
    "    idx += 1\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d03b7-1c84-4ce9-9b51-db6b2c4782ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_imgs = np.array(new_train_imgs)\n",
    "new_train_labels = np.array(new_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2fd59d-901d-4a34-9735-f1e29d157cfe",
   "metadata": {},
   "source": [
    "## Now we create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19024525-8ee0-457e-ad65-5c82cd203e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2796d9-6ee4-4f38-8e70-d31b90bdafb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(32, (5,5), activation='relu', input_shape=(400,300,3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64, (5,5), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(32, (5,5), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03905357-26ba-410d-a075-e19fdbe13e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503eedc4-fd76-4830-9d0a-f20c87e968a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3)) # Outputs are (paper, rock, scissor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb3b05-8e0f-47da-be24-b4a1f012e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eda8e7-7995-4daf-af98-a943590d9e2f",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c9791-7f3c-49d9-8b0e-763111f71c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(new_train_imgs, new_train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e48c4-8687-4f6a-9104-a751c5c1ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image, _ = capture_img(1) #  _ is because we did not add the label parameter into capture_img()\n",
    "test_image = test_image / 255\n",
    "\n",
    "prediction = model.predict(test_image)\n",
    "plt.imshow(test_image[0])\n",
    "plt.title(CLASS_NAME[np.argmax(prediction[0])]) # is "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
